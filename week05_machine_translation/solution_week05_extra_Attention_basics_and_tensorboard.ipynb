{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice: Attention Basics\n",
    "Original notebook is provided by Udacity at [github](https://github.com/udacity/deep-learning-v2-pytorch/blob/master/attention/Attention_Basics.ipynb).\n",
    "\n",
    "In this notebook, we look at how attention is implemented. We will focus on implementing attention in isolation from a larger model. That's because when implementing attention in a real-world model, a lot of the focus goes into piping the data and juggling the various vectors rather than the concepts of attention themselves.\n",
    "\n",
    "We will implement attention scoring as well as calculating an attention context vector.\n",
    "\n",
    "## Attention Scoring\n",
    "### Inputs to the scoring function\n",
    "Let's start by looking at the inputs we'll give to the scoring function. We will assume we're in the first step in the decoding phase. The first input to the scoring function is the hidden state of decoder (assuming a toy RNN with three hidden nodes -- not usable in real life, but easier to illustrate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_hidden_state = [5,1,20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize this vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2d7bebfdcc8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIYAAAEZCAYAAABSPl2zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAMr0lEQVR4nO3de4xU5R3G8e9PRBHWFRuj3LTYtLs2sdZWJFosrWIjraRQI1gTK9qm2zYRazURsDFKGhtpG1Ob/iMRgkajVqTVmKigjdLayEUEb7heqsUtbrUKBlKEwv76x4zNZn1nhh3m7O/d2edjJrBnds55hYfnXPbMvObuiPR1SPQAJE8KhiQpGJKkYEiSgiFJCoYkHRo9gKK1t7e/BewE9gP7Ojs7J4UOaJBo+mCUnd3Z2fnv6EEUzcyOB+4ExgA9wBJ3v9XMPgXcB0wE3gLmuPv2auuqGQwzOwmYCYwHHNgGPOTuWw7i/0GKsQ+4xt03mtmRwLNmthq4DHjC3W82swXAAmB+tRVVPcYws/nAvYAB64D15d/fU97AYODAqvb29mfb29s7ogdTJHd/x903ln+/E9hC6R/0TOCO8rfdAcw6kJVVfACvAsMTyw8DXqv22lwebW1t48q/HtvW1ra5ra1tavSYBuJBabexFWgFdvR5bnut15tX+VmJmb0CnOfu/+iz/NPAKndvr/C6DqAD4LbbbjttxvEzagZ0ICx/ZDlHHH4EF51z0YBve9w3x0Gpbf9vkS3q9w+qbuTGH1H+sy1b4u5Len+PmbUATwE3uftKM9vh7qN7Pb/d3Y+utp1axxhXAU+Y2WvA2+VlJwCfBa6o9KLyQD8erG97ZFuNzRRj957duDsjR4xk957dbOjcwKXnXRoylkbp82f7CWY2HHgAuNvdV5YX/8vMxrr7O2Y2Fni31naqBsPdHzWzNmAypX2VAV3Aenfff2D/K3G279zO9cuuB2B/z37O/fK5TP785OBR9WK1v6VfqzMzYCmwxd1v6fXUQ8Bc4Obyrw/WWlfNsxJ37wGeqW+oscYdM46l1y6NHkZFpb/HhpoCfA94wcw2lZddRykQfzCzH1A67phda0VD5TpGnhqcC3f/a5W1TuvPuhSMQHZIwxujYRSMQNboymggBSNSvrlQMCIVcPDZMApGpHxzoWBEUmNIWr65UDAiqTEkLd9cKBiR1BiSlm8uFIxIuvIpafnmQsGIpGMMScs3FwpGJDWGpOWbCwUjkhpD0vLNhYIRSY0hafnmQsGIpMaQJAVD0vLNhYIRSY0hafnmQsGIpMaQtHxzoWBEyrkx9DmfkqTGCJRzYygYkfLNhYIRSY0hafnmQsGIpMaQtHxzoWBEUmNIWr65UDAiqTEkLd9cKBiR9KZmScs3FwpGpJw/GVg/XQ1kZv1+HMA6l5nZu2b2Yp/l88ys08xeMrNf1VqPGiNSMYWxHPg9pUnzSpsxO5vS9FenuPseMzu21koUjEBFnK66+xozm9hn8U+Am919T/l7ak5ko11JJKvjUZ824KtmttbMnjKz02u9QI0RqJ7G6D3fXNkn5kRLOBQ4GjgDOJ3SpDaf8SoT4ikYg0ytOdEq6AJWloOwzsx6gGOA9yq9QLuSQEWclVTwJ+Cc8jbbKE2PWnXmajVGpALOSszsHuDrwDFm1gXcACwDlpVPYfcCc6vtRkDBCFXQWcnFFZ66pD/rUTAi5XvhU8GIpB+7S1q+uRiYYJTnNZc+1BiSlm8uBigY2wZkK3lLlGbOjaELXJKkXUmgnBtDwYiUby4UjEhqDEnLNxcKRiQ1hiTlfJe4ghEp31woGJG0K5G0fHOhYETSe1clLd9cKBiRdIwhafnmQsGIpMaQtHxzoWBEUmNIWr65UDAiqTEkLd9cKBiRdOVT0vLNhYIRSccYkpZvLhSMSGoMScs3FwpGJDWGJOlmYEnLNxcKRiRd4JK0fHOhYETSwaek5ZsLBSOSGkPS8s2FghEp58bQZ3BFKmC+ktTUV2b2azN7xcyeN7M/mtnoWutRMAIVNPvAcmB6n2WrgZPd/RTgVWBhrZUoGE3G3dcAH/RZtsrd95W/fAaYUGs9OsYIFHSM8X3gvlrfpMaIVMcxhpl1mNmGXo+O9MoTmzP7ObAPuLvW96oxAtXTGHVOfYWZzQVmANNqTWIDCkasAdqTmNl0YD7wNXf/z4G8RsEIVMQxRoWprxYChwOry9t8xt1/XG09CkakAhqjwtRXS/u7HgUjUM5XPhWMSPnmQsGIlHNj6DqGJKkxAukucUnKeVeiYETKNxcKRiQ1hqTlmwsFI1LOjdH0p6sLFy/kzO+cyYzLZ0QP5ZMKuLWvUZo+GBdMv4DbF98ePYykgm7ta4imD8bpXzydo1qPih5GWjM2hpld3siBDEVWx38D5WAaY1GlJ3rffrZkSb9vNho6Mm6MqmclZvZ8paeA4yq9rs/tZ862+gbX7HI+K6l1unoccB6wvc9yA/5WyIiGknxzUTMYDwMt7r6p7xNm9mQhI2qwq39xNes2rWP7h9uZOnsq8y6bx+zzZ0cPC8i7MewAbhg+WNqVAIwD+nTEmvlr+v2HP3Xx1AFJk658Bsq5MRSMSPnmQsGIpMaQtHxzoWBE0sc5Slq+uVAwIulmYEnSwaek5ZsLBSOSGkPS8s2FghFJjSFp+eZCwYikC1ySlm8uFIxIOsaQtHxzoWBEUmNIWr65UDAiqTEkLd9cKBiRcm6Mpn9Ts9RHjRFIjSFpxcyJ9jMze8nMXjSze8xsRD1DUzACNfqDU8xsPHAlMMndTwaGAd+tZ2zalUQqZk9yKHCEmf0XGAn1vUFUjRGo0Y3h7v8EfgNsBd4BPnT3VfWMTcEIZIdY/x9V5kQzs6OBmcCJlN5GPcrMLqlnbNqVRKpjV1JjTrRzgTfd/T0AM1sJfAW4q7/bUTACFXC6uhU4w8xGAruBacCGelakXUkTcfe1wApgI/ACpb/fuj4ETY0RqIgLXO5+A6UJ8g6KghEp3wufCkaknC+JKxiR8s2FghFJjSFp+eZCwYikxpC0fHOhYERSY0havrlQMCLpTc2Slm8uFIxIOsaQtHxzoWBEUmNIWr65UDAiqTEkKeePjNatfZKkxgikXYmk5ZsLBSOSGkPS8s2FghFJjTFuQLYy+OSbCzVGpCHfGIts0UBsJms3eOLNYfnmQo0Racg3hlSQby4UjEi6tU/S8s2FghFJxxiSlm8uFIxIagxJyzcXCkYkNYak5ZsLBSNSzo2hez4lSY0RKOe7xBWMQDnvShSMSPnmQsGIlHNj6OAzUgFTXwGY2TAze87MHq53aGqMQAU2xk+BLUBrvStQY0QqZrK8CcD5wO0HMzQ1RqCCGuO3wLXAkQezEjVGpDoao8bUVzOAd9392YMdmhojUD239tWY+moK8G0z+xYwAmg1s7vcvd/zoqkxIjX4GMPdF7r7BHefSGm+1T/XEwpQY4TK+TqGghGpwFy4+5PAk/W+XsEIpMaQtHxzoWBEUmNIWr65UDAiqTEkLd9cKBiR9KZmScs3FwpGJN0MLEk6+JS0fHOhYERSY0havrlQMCLl3Bi6UUeS1BiBcm4MBSNSvrlQMCKpMSQt31woGJHUGJKWby4UjEhqDEnLNxcKRqScG0NXPiVJjREo58ZQMCLlmwsFI5IaQ9LyzUXzBaN1Qiuz7pxFy5gWvMfZuGQja3+3lhFHj+DC+y5k9MTR7HhrByvmrOCjHR+FjlWNMYB69vWw6ppVdD/XzWEth9HxbAdvrH6DUy87lTefeJOnFz/NlPlTOGvBWTy+4PHQseZ8l3jN01UzO8nMpplZS5/l04sbVv12de+i+7luAPbu2st7W96jdXwr7TPb2XzHZgA237GZ9lntkcMsKehzPhuhajDM7ErgQWAe8KKZzez19C+LHFgjHPXpoxj7pbF0re2i5bgWdnXvAkrhGXXsqODRlXYl/X0MlFq7kh8Cp7n7LjObCKwws4nufitZHzrB8FHDmfPAHB696lH27twbPZzBx90rPoCX+3zdAjwK3AJsqvK6DmBD+dFRbRsFPYa7+2PufvXHy95///1udx9b/nqsu3cGjGvQPGodY3Sb2am9QrQLmAEcA3yhStiWuPuk8qPSRw8WxYCllD4y+ZaPF95///0Ac8tfzqW0i5QKrPwvPP1k6eOH97l7d+K5Ke7+dJGDq9NZwF+AF4Ce8rLrxowZc1N3d/cHwAnAVmA28EHMEPNXNRjNxMw2uPuk6HEMFkPpp6sDvUsb1IZMY0j/DKXGkH5o+mCY2XQz6zSz181sQfR4Boum3pWY2TDgVeAbQBewHrjY3V8OHdgg0OyNMRl43d3/7u57gXuBmTVeIzR/MMYDb/f6uqu8TGpo9mCkfp7TvPvOBmr2YHQBx/f6egKwLWgsg0qzB2M98DkzO9HMDqM0689DwWMaFJruDq7e3H2fmV0BPAYMA5a5+0vBwxoUmvp0VerX7LsSqZOCIUkKhiQpGJKkYEiSgiFJCoYkKRiS9D8SInBV8RFHSwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 108x324 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Let's visualize our decoder hidden state\n",
    "plt.figure(figsize=(1.5, 4.5))\n",
    "sns.heatmap(np.transpose(np.matrix(dec_hidden_state)), annot=True, cmap=sns.light_palette(\"purple\", as_cmap=True), linewidths=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first scoring function will score a single annotation (encoder hidden state), which looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = [3,12,45] #e.g. Encoder hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2af79678388>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 108x324 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's visualize the single annotation\n",
    "plt.figure(figsize=(1.5, 4.5))\n",
    "sns.heatmap(np.transpose(np.matrix(annotation)), annot=True, cmap=sns.light_palette(\"orange\", as_cmap=True), linewidths=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPLEMENT: Scoring a Single Annotation\n",
    "Let's calculate the dot product of a single annotation. NumPy's [dot()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html) is a good candidate for this operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "927"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def single_dot_attention_score(dec_hidden_state, enc_hidden_state):\n",
    "    # TODO: return the dot product of the two vectors\n",
    "    return np.asarray(dec_hidden_state).dot(np.asarray(enc_hidden_state))\n",
    "    \n",
    "single_dot_attention_score(dec_hidden_state, annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Annotations Matrix\n",
    "Let's now look at scoring all the annotations at once. To do that, here's our annotation matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = np.transpose([[3,12,45], [59,2,5], [1,43,5], [4,3,45.3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it can be visualized like this (each column is a hidden state of an encoder time step):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's visualize our annotation (each column is an annotation)\n",
    "ax = sns.heatmap(annotations, annot=True, cmap=sns.light_palette(\"orange\", as_cmap=True), linewidths=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPLEMENT: Scoring All Annotations at Once\n",
    "Let's calculate the scores of all the annotations in one step using matrix multiplication. Let's continue to us the dot scoring method\n",
    "\n",
    "<img src=\"img/scoring_functions.png\" />\n",
    "\n",
    "To do that, we'll have to transpose `dec_hidden_state` and [matrix multiply](https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html) it with `annotations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([927., 397., 148., 929.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dot_attention_score(dec_hidden_state, annotations):\n",
    "    # TODO: return the product of dec_hidden_state transpose and enc_hidden_states\n",
    "#     return np.matmul(np.asarray(dec_hidden_state).transpose(), annotations)\n",
    "    return np.asarray(dec_hidden_state).dot(annotations)\n",
    "    \n",
    "attention_weights_raw = dot_attention_score(dec_hidden_state, annotations)\n",
    "attention_weights_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these scores, can you guess which of the four vectors will get the most attention from the decoder at this time step?\n",
    "\n",
    "## Softmax\n",
    "Now that we have our scores, let's apply softmax:\n",
    "<img src=\"img/softmax.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anton\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan,  0.,  0., nan])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    x = np.array(x, dtype=np.longdouble)\n",
    "    e_x = np.exp(x)\n",
    "    return e_x / e_x.sum(axis=0) \n",
    "\n",
    "attention_weights = softmax(attention_weights_raw)\n",
    "attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even when knowing which annotation will get the most focus, it's interesting to see how drastic softmax makes the end score become. The first and last annotation had the respective scores of 927 and 929. But after softmax, the attention they'll get is 0.12 and 0.88 respectively.\n",
    "\n",
    "# Applying the scores back on the annotations\n",
    "Now that we have our scores, let's multiply each annotation by its score to proceed closer to the attention context vector. This is the multiplication part of this formula (we'll tackle the summation part in the latter cells)\n",
    "\n",
    "<img src=\"img/Context_vector.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,) (3, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    def apply_attention_scores(attention_weights, annotations):\n",
    "    # TODO: Multiple the annotations by their weights\n",
    "    return np.array(attention_weights.dot(annotations.transpose()))\n",
    "\n",
    "applied_attention = apply_attention_scores(attention_weights, annotations)\n",
    "applied_attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize how the context vector looks now that we've applied the attention scores back on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-d703e45a31c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Let's visualize our annotations after applying attention to them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied_attention\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlight_palette\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"orange\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_cmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\matrix.py\u001b[0m in \u001b[0;36mheatmap\u001b[1;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[0;32m    515\u001b[0m     plotter = _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n\u001b[0;32m    516\u001b[0m                           \u001b[0mannot_kws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbar_kws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxticklabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m                           yticklabels, mask)\n\u001b[0m\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m     \u001b[1;31m# Add the pcolormesh kwargs here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\matrix.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mplot_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplot_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;31m# Validate the mask and convet to DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[1;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;31m# by definition an array here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;31m# the dtypes will be coerced to a single dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mprep_ndarray\u001b[1;34m(values, copy)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Must pass 2-d input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Must pass 2-d input"
     ]
    }
   ],
   "source": [
    "# Let's visualize our annotations after applying attention to them\n",
    "ax = sns.heatmap(applied_attention, annot=True, cmap=sns.light_palette(\"orange\", as_cmap=True), linewidths=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrast this with the raw annotations visualized earlier in the notebook, and we can see that the second and third annotations (columns) have been nearly wiped out. The first annotation maintains some of its value, and the fourth annotation is the most pronounced.\n",
    "\n",
    "# Calculating the Attention Context Vector\n",
    "All that remains to produce our attention context vector now is to sum up the four columns to produce a single attention context vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-5d7e4d192c45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied_attention\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mattention_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_attention_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied_attention\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mattention_vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-5d7e4d192c45>\u001b[0m in \u001b[0;36mcalculate_attention_vector\u001b[1;34m(applied_attention)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalculate_attention_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied_attention\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied_attention\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mattention_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_attention_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied_attention\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mattention_vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[0;32m   2074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2075\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[1;32m-> 2076\u001b[1;33m                           initial=initial)\n\u001b[0m\u001b[0;32m   2077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2078\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "def calculate_attention_vector(applied_attention):\n",
    "    return np.sum(applied_attention, axis=1)\n",
    "\n",
    "attention_vector = calculate_attention_vector(applied_attention)\n",
    "attention_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's visualize the attention context vector\n",
    "plt.figure(figsize=(1.5, 4.5))\n",
    "sns.heatmap(np.transpose(np.matrix(attention_vector)), annot=True, cmap=sns.light_palette(\"Blue\", as_cmap=True), linewidths=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the context vector, we can concatenate it with the hidden state and pass it through a hidden layer to produce the the result of this decoding time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn:\n",
    "Now implement the _general_ and _concat_ attention scores and check it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeah, you need to initialize the matrix first (just use random, the main idea is the dimentionality)\n",
    "Wa = # <YOUR CODE HERE> \n",
    "def general_attention_score(dec_hidden_state, annotations, Wa):\n",
    "    # TODO: return the product of dec_hidden_state transpose and enc_hidden_states\n",
    "    return \n",
    "    \n",
    "attention_weights_raw = general_attention_score(dec_hidden_state, annotations, Wa)\n",
    "attention_weights_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some post-processing like above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And here you need to initialize both the vector v and the matrix Wa (\n",
    "# (again, random is fine)\n",
    "\n",
    "Wa = # <YOUR CODE HERE> \n",
    "va = # <YOUR CODE HERE> \n",
    "def concat_attention_score(dec_hidden_state, annotations, Wa, va):\n",
    "    # TODO: return the product of dec_hidden_state transpose and enc_hidden_states\n",
    "    return \n",
    "    \n",
    "attention_weights_raw = concat_attention_score(dec_hidden_state, annotations, Wa, va)\n",
    "attention_weights_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And again some post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Google Colab intro\n",
    "We roll back to the week03 practice: name generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = \" \"\n",
    "\n",
    "def read_names(path_to_file):\n",
    "    global start_token\n",
    "    \n",
    "    with open(path_to_file) as f:\n",
    "        names = f.read()[:-1].split('\\n')\n",
    "        names = [start_token + line for line in names]\n",
    "        return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    names = read_names('../datasets/names_dataset/names')\n",
    "except FileNotFoundError:\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/names_dataset/names -nc -O names\n",
    "    names = read_names('./names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    names_ru = read_names('../datasets/names_dataset/names_ru')\n",
    "except FileNotFoundError:\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/names_dataset/names_ru -nc -O names_ru\n",
    "    names_ru = read_names('./names_ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('n samples = ',len(names_ru))\n",
    "for idx in np.arange(0, len(names), 1000):\n",
    "    print(names[idx], names_ru[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length =\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)),bins=25, label='en');\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names_ru)),bins=25, alpha=0.5, label='ru');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_set_en = set()\n",
    "for name in names:\n",
    "    all_tokens_set_en.update(set(name))\n",
    "\n",
    "\n",
    "tokens_en = list(all_tokens_set_en)# <list of all unique characters in the dataset>\n",
    "\n",
    "num_tokens_en = len(tokens_en)\n",
    "print ('num_tokens = ', num_tokens_en)\n",
    "\n",
    "assert 50 < num_tokens_en < 60, \"Names should contain within 50 and 60 unique tokens depending on encoding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_set_ru = set()\n",
    "for name in names_ru:\n",
    "    all_tokens_set_ru.update(set(name))\n",
    "\n",
    "\n",
    "tokens_ru = list(all_tokens_set_ru)# <list of all unique characters in the dataset>\n",
    "\n",
    "num_tokens_ru = len(tokens_ru)\n",
    "print ('num_tokens = ', num_tokens_ru)\n",
    "\n",
    "assert 50 < num_tokens_ru < 60, \"Names should contain within 50 and 60 unique tokens depending on encoding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_id_en = {\n",
    "    token: idx for idx, token in enumerate(tokens_en)\n",
    "}\n",
    "\n",
    "token_to_id_ru = {\n",
    "    token: idx for idx, token in enumerate(tokens_ru)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(tokens_ru) == len(token_to_id_ru), \"dictionaries must have same size\"\n",
    "\n",
    "for i in range(num_tokens_ru):\n",
    "    assert token_to_id_ru[tokens_ru[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "for i in range(num_tokens_en):\n",
    "    assert token_to_id_en[tokens_en[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "    \n",
    "print(\"Seems alright!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(names, token_to_id, max_len=None, pad=None, dtype='int32', batch_first=False):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    pad = token_to_id[' ']\n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        line_ix = [token_to_id[c] for c in names[i]]\n",
    "        names_ix[i, :len(line_ix)] = line_ix\n",
    "        \n",
    "    if not batch_first: # convert [batch, time] into [time, batch]\n",
    "        names_ix = np.transpose(names_ix)\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_tokens=num_tokens_en, emb_size=16, rnn_num_units=64):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
    "        self.rnn = nn.RNN(emb_size, rnn_num_units)\n",
    "        self.hid_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        assert isinstance(x.data, torch.LongTensor)\n",
    "        h_seq, _ = self.rnn(self.emb(x))\n",
    "        next_logits = self.hid_to_logits(h_seq)\n",
    "        next_logp = F.log_softmax(next_logits, dim=-1)\n",
    "        return next_logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.NLLLoss()\n",
    "history = []\n",
    "\n",
    "# the model applies over the whole sequence\n",
    "batch_ix = to_matrix(sample(names, 32), token_to_id_en, max_len=MAX_LENGTH)\n",
    "batch_ix = torch.LongTensor(batch_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logp_seq = model(batch_ix)\n",
    "\n",
    "loss = criterion(logp_seq[:, :-1].contiguous().view(-1, num_tokens_en),\n",
    "                 batch_ix[:, 1:].contiguous().view(-1))\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(model, batch_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 16\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_ix = to_matrix(sample(names, 32), token_to_id_en, max_len=MAX_LENGTH)\n",
    "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "    \n",
    "    logp_seq = model(batch_ix)\n",
    "    \n",
    "    loss = criterion(logp_seq[:, :-1].contiguous().view(-1, num_tokens_en),\n",
    "                 batch_ix[:, 1:].contiguous().view(-1))\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    # compute loss\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # train with backprop\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    history.append(loss.data.numpy())\n",
    "    if (i+1)%100==0:\n",
    "        writer.add_scalar('train loss', history[-1], i)\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More serious: char-level machine translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to transliterate these names from English to Russian. So we need 2 models: encoder and decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_tokens=num_tokens_en, emb_size=16, rnn_num_units=64):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
    "        self.rnn = nn.RNN(emb_size, rnn_num_units)\n",
    "        self.hid_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        assert isinstance(x.data, torch.LongTensor)\n",
    "        h_seq, h_last = self.rnn(self.emb(x))\n",
    "        next_logits = self.hid_to_logits(h_seq)\n",
    "        next_logp = F.log_softmax(next_logits, dim=-1)\n",
    "        return next_logp, h_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_tokens=num_tokens_ru, emb_size=16, rnn_num_units=64):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
    "        self.rnn = nn.RNN(emb_size, rnn_num_units)\n",
    "        self.hid_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x, enc_last_state):\n",
    "        assert isinstance(x.data, torch.LongTensor)\n",
    "        h_seq, h_last = self.rnn(self.emb(x), enc_last_state)\n",
    "        next_logits = self.hid_to_logits(h_seq)\n",
    "        next_logp = F.log_softmax(next_logits, dim=-1)\n",
    "        return next_logp, h_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(self.__class__, self).__init__()\n",
    "        # YOUR CODE HERE\n",
    "    \n",
    "    def forward(self, src, trg):\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        return logp_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmt_model = Seq2Seq()\n",
    "opt = torch.optim.Adam(nmt_model.parameters())\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "indices = np.random.choice(np.arange(len(names)), size=32)\n",
    "batch_en = to_matrix(np.array(names)[indices], token_to_id=token_to_id_en, max_len=MAX_LENGTH)\n",
    "input_tensor = torch.from_numpy(batch_en).type(torch.int64)\n",
    "\n",
    "batch_ru = to_matrix(np.array(names_ru)[indices], token_to_id=token_to_id_ru, max_len=MAX_LENGTH)\n",
    "target_tensor = torch.from_numpy(batch_ru).type(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = nmt_model(input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_token_en = {idx: token for token, idx in token_to_id_en.items()}\n",
    "idx_to_token_ru = {idx: token for token, idx in token_to_id_ru.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = out.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your model here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example(idx):\n",
    "    translated = ''.join([idx_to_token_ru[x] for x in a[:, idx].numpy()])\n",
    "    original = ''.join([idx_to_token_en[x] for x in input_tensor[:, idx].numpy()])\n",
    "    print(original, translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_example(9)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
